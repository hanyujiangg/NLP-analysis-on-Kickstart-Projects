{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Content-based recommender for kickstarter projects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: rake_nltk in c:\\users\\raymond koh\\anaconda3\\lib\\site-packages (1.0.4)\n",
      "Requirement already satisfied: nltk in c:\\users\\raymond koh\\anaconda3\\lib\\site-packages (from rake_nltk) (3.4.4)\n",
      "Requirement already satisfied: six in c:\\users\\raymond koh\\anaconda3\\lib\\site-packages (from nltk->rake_nltk) (1.12.0)\n"
     ]
    }
   ],
   "source": [
    "# run this statement only once to install Rake\n",
    "!pip install rake_nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from rake_nltk import Rake\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "import re, nltk, gensim\n",
    "from nltk.tokenize import ToktokTokenizer\n",
    "from nltk.stem import wordnet\n",
    "from nltk.corpus import stopwords\n",
    "from string import punctuation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Read in and analyse the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A', 'student', 'design', 'build', 'studio', 'blurring', 'the', 'boundaries', 'of', 'architecture', 'and', 'ceramics', '(', 'and', 'birds', ').', 'A', 'patch', 'commemorating', 'the']\n",
      "['CLA', 'is', 'an', 'innovative', 'product', 'designed', 'to', 'provide', 'real', 'time', 'legal', 'resources', 'to', 'largely', 'underserved', 'individuals', '.', 'The', 'LightSpike', 'is']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Raymond Koh\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:27: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Final Main</th>\n",
       "      <th>Unnamed: 38</th>\n",
       "      <th>backers_count</th>\n",
       "      <th>blub</th>\n",
       "      <th>blurb</th>\n",
       "      <th>category</th>\n",
       "      <th>converted_pledged_amount</th>\n",
       "      <th>country</th>\n",
       "      <th>country_displayable_name</th>\n",
       "      <th>created_at</th>\n",
       "      <th>...</th>\n",
       "      <th>slug</th>\n",
       "      <th>source_url</th>\n",
       "      <th>spotlight</th>\n",
       "      <th>staff_pick</th>\n",
       "      <th>state</th>\n",
       "      <th>state_changed_at</th>\n",
       "      <th>static_usd_rate</th>\n",
       "      <th>urls</th>\n",
       "      <th>usd_pledged</th>\n",
       "      <th>usd_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>art</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A student design build studio blurring the bou...</td>\n",
       "      <td>{\"id\":25,\"name\":\"Sculpture\",\"slug\":\"art/sculpt...</td>\n",
       "      <td>1369</td>\n",
       "      <td>US</td>\n",
       "      <td>the United States</td>\n",
       "      <td>1334085321</td>\n",
       "      <td>...</td>\n",
       "      <td>bird-wall</td>\n",
       "      <td>https://www.kickstarter.com/discover/categorie...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>successful</td>\n",
       "      <td>1335762019</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{\"web\":{\"project\":\"https://www.kickstarter.com...</td>\n",
       "      <td>1369.0</td>\n",
       "      <td>international</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>art</td>\n",
       "      <td>NaN</td>\n",
       "      <td>54</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A patch commemorating the SN8 flight from Boca...</td>\n",
       "      <td>{\"id\":1,\"name\":\"Art\",\"slug\":\"art\",\"position\":1...</td>\n",
       "      <td>1229</td>\n",
       "      <td>US</td>\n",
       "      <td>the United States</td>\n",
       "      <td>1602983631</td>\n",
       "      <td>...</td>\n",
       "      <td>spacex-sn8-starship-prototype-12km-hop-patch</td>\n",
       "      <td>https://www.kickstarter.com/discover/categorie...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>successful</td>\n",
       "      <td>1608170400</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{\"web\":{\"project\":\"https://www.kickstarter.com...</td>\n",
       "      <td>1229.0</td>\n",
       "      <td>international</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>art</td>\n",
       "      <td>NaN</td>\n",
       "      <td>63</td>\n",
       "      <td>NaN</td>\n",
       "      <td>We are creating TRM movie posters for distribu...</td>\n",
       "      <td>{\"id\":21,\"name\":\"Digital Art\",\"slug\":\"art/digi...</td>\n",
       "      <td>1637</td>\n",
       "      <td>US</td>\n",
       "      <td>the United States</td>\n",
       "      <td>1341415158</td>\n",
       "      <td>...</td>\n",
       "      <td>the-real-maine-movie-poster</td>\n",
       "      <td>https://www.kickstarter.com/discover/categorie...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>successful</td>\n",
       "      <td>1342238341</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{\"web\":{\"project\":\"https://www.kickstarter.com...</td>\n",
       "      <td>1637.5</td>\n",
       "      <td>international</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>art</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A video performance piece for the self-designe...</td>\n",
       "      <td>{\"id\":24,\"name\":\"Performance Art\",\"slug\":\"art/...</td>\n",
       "      <td>2750</td>\n",
       "      <td>US</td>\n",
       "      <td>the United States</td>\n",
       "      <td>1307480670</td>\n",
       "      <td>...</td>\n",
       "      <td>voicing-islam-video-performance-piece</td>\n",
       "      <td>https://www.kickstarter.com/discover/categorie...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>successful</td>\n",
       "      <td>1310767233</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{\"web\":{\"project\":\"https://www.kickstarter.com...</td>\n",
       "      <td>2750.0</td>\n",
       "      <td>international</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>art</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Providing young artists with creative sponsors...</td>\n",
       "      <td>{\"id\":288,\"name\":\"Installations\",\"slug\":\"art/i...</td>\n",
       "      <td>75</td>\n",
       "      <td>US</td>\n",
       "      <td>the United States</td>\n",
       "      <td>1519066595</td>\n",
       "      <td>...</td>\n",
       "      <td>the-daughters-of-revolution-project</td>\n",
       "      <td>https://www.kickstarter.com/discover/categorie...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>failed</td>\n",
       "      <td>1522253573</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{\"web\":{\"project\":\"https://www.kickstarter.com...</td>\n",
       "      <td>75.0</td>\n",
       "      <td>international</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Final Main Unnamed: 38  backers_count blub  \\\n",
       "0        art         NaN             27  NaN   \n",
       "1        art         NaN             54  NaN   \n",
       "2        art         NaN             63  NaN   \n",
       "3        art         NaN             26  NaN   \n",
       "4        art         NaN              2  NaN   \n",
       "\n",
       "                                               blurb  \\\n",
       "0  A student design build studio blurring the bou...   \n",
       "1  A patch commemorating the SN8 flight from Boca...   \n",
       "2  We are creating TRM movie posters for distribu...   \n",
       "3  A video performance piece for the self-designe...   \n",
       "4  Providing young artists with creative sponsors...   \n",
       "\n",
       "                                            category  \\\n",
       "0  {\"id\":25,\"name\":\"Sculpture\",\"slug\":\"art/sculpt...   \n",
       "1  {\"id\":1,\"name\":\"Art\",\"slug\":\"art\",\"position\":1...   \n",
       "2  {\"id\":21,\"name\":\"Digital Art\",\"slug\":\"art/digi...   \n",
       "3  {\"id\":24,\"name\":\"Performance Art\",\"slug\":\"art/...   \n",
       "4  {\"id\":288,\"name\":\"Installations\",\"slug\":\"art/i...   \n",
       "\n",
       "   converted_pledged_amount country country_displayable_name  created_at  ...  \\\n",
       "0                      1369      US        the United States  1334085321  ...   \n",
       "1                      1229      US        the United States  1602983631  ...   \n",
       "2                      1637      US        the United States  1341415158  ...   \n",
       "3                      2750      US        the United States  1307480670  ...   \n",
       "4                        75      US        the United States  1519066595  ...   \n",
       "\n",
       "                                           slug  \\\n",
       "0                                     bird-wall   \n",
       "1  spacex-sn8-starship-prototype-12km-hop-patch   \n",
       "2                   the-real-maine-movie-poster   \n",
       "3         voicing-islam-video-performance-piece   \n",
       "4           the-daughters-of-revolution-project   \n",
       "\n",
       "                                          source_url spotlight  staff_pick  \\\n",
       "0  https://www.kickstarter.com/discover/categorie...      True       False   \n",
       "1  https://www.kickstarter.com/discover/categorie...      True       False   \n",
       "2  https://www.kickstarter.com/discover/categorie...      True       False   \n",
       "3  https://www.kickstarter.com/discover/categorie...      True       False   \n",
       "4  https://www.kickstarter.com/discover/categorie...     False       False   \n",
       "\n",
       "        state  state_changed_at  static_usd_rate  \\\n",
       "0  successful        1335762019              1.0   \n",
       "1  successful        1608170400              1.0   \n",
       "2  successful        1342238341              1.0   \n",
       "3  successful        1310767233              1.0   \n",
       "4      failed        1522253573              1.0   \n",
       "\n",
       "                                                urls  usd_pledged  \\\n",
       "0  {\"web\":{\"project\":\"https://www.kickstarter.com...       1369.0   \n",
       "1  {\"web\":{\"project\":\"https://www.kickstarter.com...       1229.0   \n",
       "2  {\"web\":{\"project\":\"https://www.kickstarter.com...       1637.5   \n",
       "3  {\"web\":{\"project\":\"https://www.kickstarter.com...       2750.0   \n",
       "4  {\"web\":{\"project\":\"https://www.kickstarter.com...         75.0   \n",
       "\n",
       "        usd_type  \n",
       "0  international  \n",
       "1  international  \n",
       "2  international  \n",
       "3  international  \n",
       "4  international  \n",
       "\n",
       "[5 rows x 41 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "\n",
    "#Dataset\n",
    "from nltk.corpus import PlaintextCorpusReader\n",
    "\n",
    "art = PlaintextCorpusReader('data/Train/Art', '.+\\.txt')\n",
    "tech = PlaintextCorpusReader('data/Train/Tech', '.+\\.txt')\n",
    "\n",
    "art_docs1 = [art.words(fid) for fid in art.fileids()]\n",
    "tech_docs1 = [tech.words(fid) for fid in tech.fileids()]\n",
    "\n",
    "print(art_docs1[0][0:20])\n",
    "print(tech_docs1[0][0:20])\n",
    "\n",
    "\n",
    "#DY dataset \n",
    "path = r'./data/' # use your path\n",
    "all_files = glob.glob(path + \"/*.csv\")\n",
    "\n",
    "li = []\n",
    "\n",
    "for filename in all_files:\n",
    "    df = pd.read_csv(filename, index_col=None, header=0)\n",
    "    li.append(df)\n",
    "\n",
    "frame = pd.concat(li, axis=0, ignore_index=True)\n",
    "\n",
    "# df = pd.read_csv('Kickstarter057.csv')\n",
    "\n",
    "df = frame\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1\n",
      "Dictionary(5784 unique tokens: ['aalborg', 'ab', 'abaddon', 'abalon', 'abandon']...)\n",
      "<class 'list'>\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-0eb69a335625>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[0mclassifier\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mNaiveBayesClassifier\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_labeled_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m \u001b[0mtest_doc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mall_data_as_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;31m#35 is crime article. Until 99 are all crime\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m \u001b[1;31m#print(all_data_as_dict[0])\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclassify\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_doc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "# Combine the categories of the corpus\n",
    "all_docs1 = art_docs1 + tech_docs1\n",
    "num_art_docs = len(art_docs1)\n",
    "print(num_art_docs)\n",
    "print (len(tech_docs1))\n",
    "\n",
    "# Processsing for stopwords, alphabetic words, Stemming \n",
    "\n",
    "all_docs2 = [[w.lower() for w in doc] for doc in all_docs1]\n",
    "\n",
    "import re\n",
    "all_docs3 = [[w for w in doc if re.search('^[a-z]+$',w)] for doc in all_docs2]\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "stop_list = stopwords.words('english')\n",
    "all_docs4 = [[w for w in doc if w not in stop_list] for doc in all_docs3]\n",
    "\n",
    "from nltk.stem.porter import *\n",
    "stemmer = PorterStemmer()\n",
    "all_docs5 = [[stemmer.stem(w) for w in doc] for doc in all_docs4]\n",
    "\n",
    "#Create dictionary\n",
    "from gensim import corpora\n",
    "dictionary = corpora.Dictionary(all_docs5)\n",
    "print(dictionary)\n",
    "\n",
    "# Convert all documents to TF Vectors\n",
    "all_tf_vectors = [dictionary.doc2bow(doc) for doc in all_docs5]\n",
    "\n",
    "#Label the trained data. Since the folder name is the label, I use the same labels.\n",
    "\n",
    "all_data_as_dict = [{id:1 for (id, tf_value) in vec} for vec in all_tf_vectors]\n",
    "print(type(all_data_as_dict))\n",
    "\n",
    "#print(all_data_as_dict)\n",
    "\n",
    "art_data = [(d, 'ART') for d in all_data_as_dict[0:num_art_docs]]\n",
    "tech_data = [(d, 'TECH') for d in all_data_as_dict[num_art_docs:]]\n",
    "all_labeled_data = art_data + tech_data\n",
    "\n",
    "#Generate the trained classifier\n",
    "classifier = nltk.NaiveBayesClassifier.train(all_labeled_data)\n",
    "\n",
    "test_doc = all_data_as_dict[4] #35 is crime article. Until 99 are all crime\n",
    "#print(all_data_as_dict[0])\n",
    "print(classifier.classify(test_doc))\n",
    "\n",
    "\n",
    "#Processing data for DY\n",
    "def extract_cat(text):\n",
    "    text = text.split(\",\")\n",
    "    \n",
    "    text = text[1] + \" \" +text[2]\n",
    "    \n",
    "\n",
    "    text = text.replace (\"/\", \" \")\n",
    "    \n",
    "    \n",
    "    text = text.replace (\"name\", \"\")\n",
    "    text = text.replace (\"slug\", \"\")\n",
    "    \n",
    "    text = text.replace ('\"', \"\")\n",
    "    text = text.replace ('{', \"\")\n",
    "    text = text.replace (':', \"\")\n",
    "    \n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"\\'\\n\", \" \", text)\n",
    "    text = re.sub(r\"\\'\\xa0\", \" \", text)\n",
    "    text = re.sub('\\s+', ' ', text) # matches all whitespace characters\n",
    "    text = text.strip(' ')\n",
    "    return text\n",
    "\n",
    "\n",
    "\n",
    "df['category'] = df['category'].apply(lambda x: extract_cat(x))\n",
    "\n",
    "\n",
    "df.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = df[['name','category','blurb']]\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import nltk\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem import WordNetLemmatizer,PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stemmer = PorterStemmer() \n",
    "\n",
    "def preprocess(sentence):\n",
    "    sentence=str(sentence)\n",
    "    sentence = sentence.lower()\n",
    "    sentence=sentence.replace('{html}',\"\") \n",
    "    cleanr = re.compile('<.*?>')\n",
    "    cleantext = re.sub(cleanr, '', sentence)\n",
    "    rem_url=re.sub(r'http\\S+', '',cleantext)\n",
    "    rem_num = re.sub('[0-9]+', '', rem_url)\n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    tokens = tokenizer.tokenize(rem_num)  \n",
    "    filtered_words = [w for w in tokens if len(w) > 2 if not w in stopwords.words('english')]\n",
    "    stem_words=[stemmer.stem(w) for w in filtered_words]\n",
    "    lemma_words=[lemmatizer.lemmatize(w) for w in stem_words]\n",
    "    return \" \".join(filtered_words)\n",
    "\n",
    "\n",
    "df['blurb']=df['blurb'].map(lambda s:preprocess(s)) \n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfcat = df['category']\n",
    "\n",
    "dfcat.head \n",
    "\n",
    "num_dfcat = len(dfcat)\n",
    "\n",
    "#print(num_dfcat)\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "dfcat = dfcat.apply(word_tokenize)\n",
    "dfcat.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim import corpora\n",
    "\n",
    "dictionary = corpora.Dictionary(dfcat)\n",
    "\n",
    "print(dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
